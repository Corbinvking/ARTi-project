# ðŸ”„ Full Database Sync & Refresh Plan

**Complete data refresh from CSV to ensure 100% accuracy across all systems**

---

## ðŸ“Š Scope

### **CSV Data** (`full-databse-chunk.csv`)
- **Total Campaigns**: 653
- **Unique Clients**: 203
- **Salespersons**: 19
- **Status Breakdown**:
  - Complete: 325 (50%)
  - Active: 265 (41%)
  - Cancelled: 43 (7%)
  - Unreleased: 14 (2%)
  - Other: 6 (<1%)

### **Goal**
Create a **complete, accurate, synchronized database** with:
1. âœ… All 653 campaigns from CSV
2. âœ… All 203 clients properly linked
3. âœ… All vendors tracked
4. âœ… Spotify for Artists URLs collected
5. âœ… Stream data for all active/complete campaigns (~590 campaigns)
6. âœ… Playlist data linked correctly

---

## ðŸŽ¯ Master Workflow

```
CSV (653 campaigns) 
  â†“
Stage 1: Parse & Normalize CSV Data
  â†“
Stage 2: Create/Update Clients (203 unique)
  â†“
Stage 3: Create/Update Vendors (from CSV vendor column)
  â†“
Stage 4: Create/Update Campaigns (653 total)
  â†“
Stage 5: Collect SFA URLs (for campaigns without them)
  â†“
Stage 6: Scrape Stream Data (active + complete campaigns)
  â†“
Stage 7: Import Playlist Data
  â†“
Stage 8: Link Everything (campaigns â†” clients â†” vendors â†” playlists)
  â†“
Stage 9: Verify Data Integrity
  â†“
Stage 10: Deploy to Production
```

---

## ðŸ“‹ Database Structure

### **Current Tables**

#### `spotify_campaigns`
```sql
- campaign (TEXT) -- "Artist - Song Name"
- client (TEXT) -- Client name
- goal (TEXT) -- Stream goal
- salesperson (TEXT) -- Who sold it
- url (TEXT) -- Spotify track URL
- sfa (TEXT) -- Spotify for Artists URL
- status (TEXT) -- Active, Complete, etc.
- vendor (TEXT) -- Who's running it
- start_date (TEXT)
- sale_price (TEXT)
- client_email (TEXT)
- vendor_email (TEXT)
- notes (TEXT)
... + 15 more columns
```

#### `clients`
```sql
- id (UUID)
- name (TEXT)
- emails (TEXT[])
- phone (TEXT)
- contact_person (TEXT)
```

#### `vendors`
```sql
- id (UUID)
- name (TEXT)
- email (TEXT)
- contact_person (TEXT)
```

#### `campaign_playlists`
```sql
- campaign_id (INT) â†’ spotify_campaigns(id)
- playlist_name (TEXT)
- playlist_curator (TEXT)
- streams_28d (INT)
- streams_7d (INT)
- streams_12m (INT)
- date_added (TEXT)
```

---

## ðŸ”¨ Stage-by-Stage Implementation

### **Stage 1: CSV Parsing & Normalization**

**Script**: `scripts/parse_all_campaigns_csv.js`

**What it does**:
- âœ… Read `Spotify Playlisting-All Campaigns.csv`
- âœ… Clean and normalize data
- âœ… Extract campaign name, client, salesperson, status
- âœ… Parse Spotify URLs (if present)
- âœ… Identify which campaigns need SFA URLs

**Output**:
```json
{
  "total_campaigns": 585,
  "by_status": {
    "active": 248,
    "complete": 291,
    "cancelled": 31,
    "unreleased": 9
  },
  "clients": [...],
  "vendors": [...],
  "campaigns": [...]
}
```

---

### **Stage 2: Client Creation/Update**

**Script**: `scripts/sync_clients_from_csv.js`

**What it does**:
- âœ… Extract all unique clients (190)
- âœ… Check if client exists in database
- âœ… Create new clients OR update existing
- âœ… Normalize email addresses
- âœ… Link to campaigns

**Data mapping**:
```
CSV "Client" â†’ clients.name
CSV "Client Email" â†’ clients.emails[]
```

---

### **Stage 3: Vendor Creation/Update**

**Script**: `scripts/sync_vendors_from_csv.js`

**What it does**:
- âœ… Extract all unique vendors
- âœ… Check if vendor exists
- âœ… Create new vendors OR update existing
- âœ… Link vendor emails

**Data mapping**:
```
CSV "Vendor" â†’ vendors.name
CSV "Vendor Email" â†’ vendors.email
```

---

### **Stage 4: Campaign Creation/Update**

**Script**: `scripts/sync_campaigns_from_csv.js`

**What it does**:
- âœ… For each of 585 campaigns:
  - Check if campaign exists (by name or URL)
  - Create new OR update existing
  - Map ALL CSV columns to database columns
  - Link to client_id and vendor_id
  - Preserve existing SFA URLs

**Data mapping**:
```
CSV "Campaign" â†’ spotify_campaigns.campaign
CSV "Client" â†’ spotify_campaigns.client (also link to clients table)
CSV "Goal" â†’ spotify_campaigns.goal
CSV "Salesperson" â†’ spotify_campaigns.salesperson
CSV "Status" â†’ spotify_campaigns.status
CSV "URL" â†’ spotify_campaigns.url
CSV "SFA" â†’ spotify_campaigns.sfa
CSV "Vendor" â†’ spotify_campaigns.vendor (also link to vendors table)
CSV "Start Date" â†’ spotify_campaigns.start_date
CSV "Sale price" â†’ spotify_campaigns.sale_price
... all 25 columns
```

**Important**: 
- Update existing campaigns (don't create duplicates)
- Preserve existing `sfa` URLs if present
- Update status, salesperson, etc. from CSV

---

### **Stage 5: SFA URL Collection**

**Script**: `roster_scraper/run_roster_scraper.py` (modified)

**What it does**:
- âœ… Get all campaigns where `sfa` is NULL or empty
- âœ… Filter by status: Active, Complete
- âœ… Search Roster for each artist
- âœ… Find matching songs
- âœ… Extract SFA URLs
- âœ… Update `spotify_campaigns.sfa` column

**Target campaigns**: 
- Active (248) + Complete (291) = 539 campaigns
- Estimate: ~300-400 will have SFA URLs available

---

### **Stage 6: Stream Data Scraping**

**Script**: `spotify_scraper/run_roster_urls.py` (modified)

**What it does**:
- âœ… Get all campaigns with `sfa` URLs
- âœ… Filter: Active + Complete statuses
- âœ… Scrape playlist data (28d, 7d, 12m)
- âœ… Save JSON files per song

**Estimated time**: 
- ~400 songs Ã— 2 min = ~13 hours
- Can run overnight

---

### **Stage 7: Playlist Data Import**

**Script**: `scripts/import-roster-scraped-data.js` (existing)

**What it does**:
- âœ… Read all scraped JSON files
- âœ… Match to campaigns by track ID
- âœ… Create `campaign_playlists` records
- âœ… Link playlists to campaigns

**Result**:
- Thousands of playlist records
- Stream data for 28d, 7d, 12m
- Algorithmic vs vendor playlist classification

---

### **Stage 8: Relationship Linking**

**Script**: `scripts/link_all_relationships.js`

**What it does**:
- âœ… Link campaigns â†” clients (via client_id foreign key)
- âœ… Link campaigns â†” vendors (via vendor_id foreign key)
- âœ… Link campaigns â†” playlists (via campaign_playlists)
- âœ… Create `campaign_groups` for multi-song campaigns
- âœ… Verify all relationships are correct

---

### **Stage 9: Data Verification**

**Script**: `scripts/verify_database_integrity.js`

**What it does**:
- âœ… Count total campaigns (should be 585)
- âœ… Count clients (should be 190)
- âœ… Count vendors
- âœ… Check for orphaned records
- âœ… Verify all statuses are valid
- âœ… Check all active campaigns have data
- âœ… Generate integrity report

**Report includes**:
```
âœ… Total campaigns: 585
âœ… Active campaigns: 248
âœ… Complete campaigns: 291
âœ… Campaigns with SFA URLs: ~400
âœ… Campaigns with playlist data: ~350
âœ… Clients created: 190
âœ… Vendors created: ~15
âœ… Playlist records: ~5,000+
âš ï¸  Campaigns missing data: ~35
âš ï¸  Orphaned records: 0
```

---

### **Stage 10: Production Deployment**

**Script**: `scripts/deploy_to_production.sh`

**What it does**:
- âœ… Upload all scraped JSON files
- âœ… Run all sync scripts on production
- âœ… Import playlist data
- âœ… Verify production database
- âœ… Test production UI

---

## ðŸ”„ Master Script

### **`scripts/run_full_database_sync.py`**

**One command to rule them all:**

```bash
python scripts/run_full_database_sync.py \
  --csv "Spotify Playlisting-All Campaigns.csv" \
  --scrape-sfa \
  --scrape-streams \
  --deploy-production
```

**Options:**
```bash
# Parse and sync only (no scraping)
--sync-only

# Scrape SFA URLs only
--scrape-sfa-only

# Scrape stream data only (if SFA URLs exist)
--scrape-streams-only

# Local only (test first)
--local-only

# Production deployment
--deploy-production

# Dry run (show what would happen)
--dry-run
```

---

## ðŸ“Š Data Flow Diagram

```
Spotify Playlisting-All Campaigns.csv (585 campaigns)
â”‚
â”œâ”€â–º Parse & Normalize
â”‚   â”œâ”€â–º 190 Unique Clients
â”‚   â”œâ”€â–º ~15 Unique Vendors
â”‚   â””â”€â–º 585 Campaigns
â”‚
â”œâ”€â–º Create/Update Database Records
â”‚   â”œâ”€â–º clients table (190 records)
â”‚   â”œâ”€â–º vendors table (~15 records)
â”‚   â””â”€â–º spotify_campaigns table (585 records)
â”‚
â”œâ”€â–º Collect SFA URLs
â”‚   â”œâ”€â–º Search Roster for ~400 campaigns
â”‚   â””â”€â–º Update spotify_campaigns.sfa column
â”‚
â”œâ”€â–º Scrape Stream Data
â”‚   â”œâ”€â–º ~400 campaigns with SFA URLs
â”‚   â””â”€â–º ~800 JSON files (2 per campaign avg)
â”‚
â”œâ”€â–º Import Playlist Data
â”‚   â””â”€â–º campaign_playlists table (~5,000+ records)
â”‚
â””â”€â–º Deploy to Production
    â”œâ”€â–º Upload data files
    â”œâ”€â–º Run sync scripts
    â””â”€â–º Verify in UI
```

---

## âš ï¸ Important Considerations

### **Duplicate Prevention**
- âœ… Check for existing campaigns by name OR URL
- âœ… Update existing records instead of creating duplicates
- âœ… Merge data intelligently (preserve SFA URLs, update status)

### **Data Preservation**
- âœ… Don't delete existing playlist data
- âœ… Preserve manually entered SFA URLs
- âœ… Keep historical data (don't overwrite timestamps)

### **Performance**
- âœ… Batch database operations (100 records at a time)
- âœ… Show progress bars
- âœ… Allow resume if interrupted
- âœ… Parallel scraping where possible

### **Error Handling**
- âœ… Log all errors
- âœ… Continue on individual failures
- âœ… Generate error report at end
- âœ… Retry failed operations

---

## ðŸ“ˆ Expected Results

### **Database State After Sync**

| Table | Records | Notes |
|-------|---------|-------|
| `clients` | 190 | All unique clients |
| `vendors` | ~15 | All vendors from CSV |
| `spotify_campaigns` | 585 | All campaigns, all statuses |
| `campaign_playlists` | ~5,000+ | Playlist data for active/complete |

### **Coverage**

| Metric | Expected | Percentage |
|--------|----------|------------|
| **Total Campaigns** | 585 | 100% |
| **With Spotify URLs** | ~500 | 85% |
| **With SFA URLs** | ~400 | 68% |
| **With Playlist Data** | ~350 | 60% |
| **Active/Complete** | 539 | 92% |

---

## ðŸš€ Implementation Order

### **Phase 1: Database Sync** (1 hour)
1. âœ… Parse CSV
2. âœ… Create/update clients
3. âœ… Create/update vendors
4. âœ… Create/update campaigns

### **Phase 2: URL Collection** (3-4 hours)
1. âœ… Search Roster for ~400 campaigns
2. âœ… Extract SFA URLs
3. âœ… Update database

### **Phase 3: Stream Scraping** (12-15 hours)
1. âœ… Scrape ~400 campaigns
2. âœ… Save JSON files
3. âœ… Can run overnight

### **Phase 4: Import & Verify** (1 hour)
1. âœ… Import playlist data
2. âœ… Link relationships
3. âœ… Verify integrity

### **Phase 5: Production** (30 min)
1. âœ… Upload to production
2. âœ… Run imports
3. âœ… Verify UI

**Total Time: ~16-20 hours (mostly automated)**

---

## ðŸ“ Next Steps

1. **Review this plan** - Make sure approach is correct
2. **Create sync scripts** - Build the database sync tools
3. **Test on subset** - Try with 10 campaigns first
4. **Run full sync** - Process all 585 campaigns
5. **Verify results** - Check database and UI
6. **Deploy to production** - Make it live

---

## ðŸŽ¯ Success Criteria

âœ… **All 585 campaigns** in database  
âœ… **All 190 clients** created/linked  
âœ… **All vendors** created/linked  
âœ… **~400 SFA URLs** collected  
âœ… **~350 campaigns** with playlist data  
âœ… **~5,000+ playlist records** created  
âœ… **Data visible in UI** (local and production)  
âœ… **All relationships** correctly linked  
âœ… **Zero duplicates** in database  
âœ… **100% data accuracy** from CSV  

---

**Ready to build this system?** ðŸš€

This will be the **definitive data refresh** that ensures everything is correct!

