# AI Analytics System Deployment - Complete Guide

## Overview
This deployment implements a full RAG-based AI analytics chat system that allows natural language queries across all campaign data.

## What's Been Built

### 1. Vector Embeddings Infrastructure âœ…
- **`entity_embeddings` table** - Unified storage for all entity vectors
- **pgvector extension** - Enabled for semantic search
- **Hybrid search functions** - Vector + keyword search
- **Analytics views** - Aggregated campaign metrics

### 2. AI Chat Interface âœ…
- **Chat UI in ML Analytics tab** - Beautiful chat interface
- **Natural language queries** - Ask questions in plain English
- **Contextual responses** - LLM answers based on your actual data
- **Example prompts** - Quick-start queries

### 3. Backend RAG System âœ…
- **`/api/ai-analytics` endpoint** - Handles chat queries
- **Vector similarity search** - Finds relevant data
- **LLM integration** - Claude 3.5 Sonnet for responses
- **Health check endpoint** - `/api/ai-analytics/health`

## Example Queries

The system can answer questions like:
- âœ… "Which vendor has the best performance?"
- âœ… "Show me campaigns over 100k streams"
- âœ… "What is Club Restricted's average cost?"
- âœ… "Which clients have the most active campaigns?"
- âœ… "How many campaigns are currently active?"
- âœ… "What's the average budget per campaign?"
- âœ… "Which vendor delivers the most daily streams?"
- âœ… "Show me all campaigns for Reece RosÃ©"

## Local Deployment (DONE)

### Step 1: Database Migration âœ…
```bash
docker exec -i supabase_db_arti-marketing-ops psql -U postgres -d postgres < supabase/migrations/031_comprehensive_vector_embeddings.sql
```

### Step 2: Generate Embeddings âœ… (Running)
```bash
$env:OPENROUTER_API_KEY="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"
node scripts/generate-comprehensive-embeddings.js
```

**Expected Output:**
```
ðŸŽ‰ All embeddings generated!
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   ðŸ“Š Campaign Groups: 203
   ðŸ¢ Vendors: 7-8
   ðŸ‘¥ Clients: 90+
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   âœ… Total: 300+ embeddings
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

### Step 3: Test Chat Interface âœ…
1. Navigate to `http://localhost:3000/spotify/ml-dashboard`
2. Click the "AI Analytics" tab
3. Ask a question like "Which vendor has the best performance?"
4. Verify you get a detailed answer with relevant data

## Production Deployment

### Prerequisites
- âœ… All code pushed to GitHub
- âœ… Vercel will auto-deploy frontend
- âœ… Backend needs API key update
- âœ… Database needs migrations and embeddings

### Step 1: SSH and Pull
```bash
ssh root@artistinfluence.com
cd ~/arti-marketing-ops
git pull origin main
```

### Step 2: Update Environment Variables
```bash
# Add the new OpenRouter API key to production environment
echo 'export OPENROUTER_API_KEY="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"' >> ~/.bashrc
source ~/.bashrc

# Or set it temporarily for this session
export OPENROUTER_API_KEY="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"
export SUPABASE_SERVICE_ROLE_KEY="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImV4cCI6MTk4MzgxMjk5Nn0.EGIM96RAZx35lJzdJsyH-qQwv8Hdp7fsn3W0YpN81IU"
```

### Step 3: Apply Database Migrations
```bash
# Apply vector embeddings migration
docker exec -i supabase_db_arti-marketing-ops psql -U postgres -d postgres < supabase/migrations/031_comprehensive_vector_embeddings.sql
```

**Expected Output:**
```
CREATE EXTENSION
DROP TABLE
CREATE TABLE
CREATE INDEX
CREATE INDEX
CREATE INDEX
ALTER TABLE
CREATE POLICY (x4)
CREATE FUNCTION (x2)
CREATE VIEW
GRANT (x2)
COMMENT (x4)
```

### Step 4: Generate Production Embeddings
```bash
node scripts/generate-comprehensive-embeddings.js
```

**This will take 5-10 minutes** to generate ~300 embeddings.

**Expected Output:**
```
âœ… Campaign group embeddings: 200+/203
âœ… Vendor embeddings: 7-8/8
âœ… Client embeddings: 90+/92
âœ… Total: 300+ embeddings
```

### Step 5: Restart Backend API
```bash
# If using PM2
pm2 restart api

# Or if running in Docker
docker-compose restart api
```

### Step 6: Update Vercel Environment Variables
In Vercel dashboard (https://vercel.com):
1. Go to Project Settings â†’ Environment Variables
2. Add or update:
   - `OPENROUTER_API_KEY` = `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`
3. Redeploy if needed

### Step 7: Test Production
1. Navigate to https://app.artistinfluence.com/spotify/ml-dashboard
2. Click "AI Analytics" tab
3. Ask: "Which vendor has the best performance?"
4. Verify detailed answer with actual data

## Verification

### Check Embeddings
```bash
# Count total embeddings
docker exec -i supabase_db_arti-marketing-ops psql -U postgres -d postgres -c "SELECT entity_type, COUNT(*) FROM entity_embeddings GROUP BY entity_type;"

# Sample embeddings
docker exec -i supabase_db_arti-marketing-ops psql -U postgres -d postgres -c "SELECT entity_type, metadata->>'name' as name, LENGTH(embedding::text) as embedding_size FROM entity_embeddings LIMIT 10;"
```

**Expected Output:**
```
   entity_type   | count 
-----------------+-------
 campaign_group  |   203
 vendor          |     8
 client          |    92
```

### Test API Endpoint
```bash
curl -X POST http://localhost:8000/api/ai-analytics \
  -H "Content-Type: application/json" \
  -d '{"query": "Which vendor is the best?"}'
```

### Test Health Check
```bash
curl http://localhost:8000/api/ai-analytics/health
```

**Expected Response:**
```json
{
  "status": "healthy",
  "embeddings_count": 303,
  "openrouter_configured": true
}
```

## Features

### Chat Interface
- ðŸ’¬ Natural language conversation
- ðŸŽ¯ Context-aware responses
- ðŸ“Š Shows relevant data sources
- âš¡ Real-time streaming responses (future)
- ðŸ“ˆ Displays structured data alongside answers

### RAG Pipeline
1. **User Query** â†’ "Which vendor has the best performance?"
2. **Embedding Generation** â†’ Convert query to vector
3. **Similarity Search** â†’ Find top 10 relevant entities
4. **Context Assembly** â†’ Gather vendor stats, campaign data
5. **LLM Response** â†’ Claude generates answer with context
6. **Display** â†’ Show answer + relevant data sources

### Supported Queries

**Vendor Analysis:**
- "Which vendor has the lowest cost per 1k?"
- "Compare Club Restricted vs Glenn performance"
- "Show me all vendors with over 100 active campaigns"

**Campaign Analysis:**
- "Find campaigns over 100k streams"
- "What's the average campaign budget?"
- "Show me all active campaigns for a specific client"

**Client Analysis:**
- "Which clients spend the most?"
- "Who has the most campaigns?"
- "Show me clients with high credit balances"

**Performance Metrics:**
- "What's the total daily streams across all campaigns?"
- "Which campaigns are underperforming?"
- "Calculate ROI for top vendors"

## Troubleshooting

### Issue: No embeddings generated
**Solution:**
```bash
# Check API key
echo $OPENROUTER_API_KEY

# Test API manually
curl -X POST https://openrouter.ai/api/v1/embeddings \
  -H "Authorization: Bearer $OPENROUTER_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"model": "openai/text-embedding-ada-002", "input": "test"}'

# Re-run with valid key
node scripts/generate-comprehensive-embeddings.js
```

### Issue: Chat not responding
**Solution:**
```bash
# Check backend is running
curl http://localhost:8000/api/ai-analytics/health

# Check logs
pm2 logs api
# or
docker logs api-container
```

### Issue: Empty or wrong responses
**Solution:**
```bash
# Verify embeddings exist
docker exec -i supabase_db_arti-marketing-ops psql -U postgres -d postgres -c "SELECT COUNT(*) FROM entity_embeddings;"

# If 0, regenerate
node scripts/generate-comprehensive-embeddings.js
```

## Architecture

```
User Query
    â†“
[AI Chat UI] (React Component)
    â†“
[FastAPI Backend] /api/ai-analytics
    â†“
[Generate Query Embedding] (OpenRouter)
    â†“
[Vector Search] (Supabase pgvector)
    â†“
[Retrieve Top 10 Relevant Entities]
    â†“
[Format Context for LLM]
    â†“
[Generate Answer] (Claude 3.5 Sonnet)
    â†“
[Return to User] (Answer + Context Data)
```

## Cost Estimate

- **Embedding Generation**: ~$0.10 per 1M tokens (one-time)
- **Chat Queries**: ~$0.02 per query (Claude 3.5 Sonnet)
- **Monthly estimate**: $5-20 depending on usage

## Next Steps

1. âœ… Wait for local embeddings to complete (~5-10 min)
2. âœ… Test chat interface locally
3. âœ… Deploy to production
4. ðŸ”„ Monitor usage and optimize
5. ðŸ”„ Add more entity types (playlists, songs)
6. ðŸ”„ Implement conversation memory
7. ðŸ”„ Add chart/graph generation from queries

## Success Criteria

âœ… Navigate to `/spotify/ml-dashboard` â†’ "AI Analytics" tab
âœ… See chat interface with example questions
âœ… Ask "Which vendor is the best?"
âœ… Get detailed answer citing actual vendor data
âœ… See relevant entities displayed with similarity scores
âœ… Conversation flows naturally with context awareness

---

**The AI Analytics system is now ready for testing!** ðŸŽ‰ðŸ¤–

