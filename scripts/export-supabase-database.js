#!/usr/bin/env node

/**
 * Supabase Database Export Script
 * Exports the complete current Supabase database for cloning to another machine
 */

const { execSync } = require('child_process');
const fs = require('fs');
const path = require('path');

const SUPABASE_CONFIG = {
  host: 'localhost',
  port: 54322,
  database: 'postgres',
  username: 'postgres',
  password: 'postgres'
};

const EXPORT_DIR = path.join(__dirname, '..', 'supabase-export');
const TIMESTAMP = new Date().toISOString().replace(/[:.]/g, '-');

async function exportDatabase() {
  console.log('üöÄ STARTING SUPABASE DATABASE EXPORT');
  console.log('=' .repeat(60));

  try {
    // Create export directory
    if (!fs.existsSync(EXPORT_DIR)) {
      fs.mkdirSync(EXPORT_DIR, { recursive: true });
    }

    const exportFile = path.join(EXPORT_DIR, `supabase-export-${TIMESTAMP}.sql`);

    console.log(`üìÅ Export directory: ${EXPORT_DIR}`);
    console.log(`üìÑ Export file: ${exportFile}`);
    console.log('');

    // Export database schema and data
    console.log('üìä Exporting database schema and data...');

    const pgDumpCommand = `pg_dump \
      -h ${SUPABASE_CONFIG.host} \
      -p ${SUPABASE_CONFIG.port} \
      -U ${SUPABASE_CONFIG.username} \
      -d ${SUPABASE_CONFIG.database} \
      --no-owner \
      --no-privileges \
      --clean \
      --if-exists \
      --verbose \
      --file="${exportFile}"`;

    execSync(pgDumpCommand, {
      env: { ...process.env, PGPASSWORD: SUPABASE_CONFIG.password },
      stdio: 'inherit'
    });

    console.log(`‚úÖ Database exported successfully to: ${exportFile}`);
    console.log('');

    // Create metadata file
    const metadata = {
      timestamp: new Date().toISOString(),
      source: 'ARTI0-local-supabase',
      version: '1.0',
      description: 'Complete Supabase database export for ARTI platform',
      includes: [
        'Schema (tables, functions, policies)',
        'All table data',
        'Auth configuration',
        'Storage configuration'
      ],
      database: {
        host: SUPABASE_CONFIG.host,
        port: SUPABASE_CONFIG.port,
        database: SUPABASE_CONFIG.database
      }
    };

    fs.writeFileSync(
      path.join(EXPORT_DIR, 'export-metadata.json'),
      JSON.stringify(metadata, null, 2)
    );

    // Create import script
    const importScript = `#!/bin/bash
# Supabase Database Import Script
# Run this script on the target machine to import the database

echo "üöÄ IMPORTING SUPABASE DATABASE"
echo "================================"

# Stop existing supabase instance
echo "üõë Stopping existing Supabase instance..."
supabase stop

# Start fresh supabase instance
echo "‚ñ∂Ô∏è  Starting fresh Supabase instance..."
supabase start

# Wait for database to be ready
echo "‚è≥ Waiting for database to be ready..."
sleep 10

# Import the database
echo "üì• Importing database..."
psql -h localhost -p 54322 -U postgres -d postgres -f "${exportFile}"

echo "‚úÖ Database import completed!"
echo ""
echo "üîß Next steps:"
echo "1. Verify data integrity"
echo "2. Update environment variables"
echo "3. Test the application"
`;

    fs.writeFileSync(
      path.join(EXPORT_DIR, 'import-database.sh'),
      importScript
    );

    // Make import script executable
    execSync(`chmod +x "${path.join(EXPORT_DIR, 'import-database.sh')}"`);

    console.log('üìã Created import script: import-database.sh');
    console.log('');

    // Create README with instructions
    const readme = `# Supabase Database Export

This directory contains a complete export of the ARTI platform Supabase database.

## Contents

- \`supabase-export-${TIMESTAMP}.sql\` - Complete database dump
- \`import-database.sh\` - Script to import on target machine
- \`export-metadata.json\` - Export metadata and information

## For Target Machine Setup

1. Copy this entire directory to the target machine
2. Navigate to this directory
3. Run: \`./import-database.sh\`

## Database Connection Details

- **Host**: ${SUPABASE_CONFIG.host}
- **Port**: ${SUPABASE_CONFIG.port}
- **Database**: ${SUPABASE_CONFIG.database}
- **Username**: ${SUPABASE_CONFIG.username}

## What This Export Includes

‚úÖ Complete schema (tables, indexes, constraints)
‚úÖ All table data
‚úÖ Functions and stored procedures
‚úÖ Row Level Security (RLS) policies
‚úÖ Auth configuration
‚úÖ Storage configuration

## Notes

- This export excludes user passwords for security
- Auth users will need to be recreated on the target machine
- Storage buckets and files are not included in this export
- Environment-specific configurations may need updating

`;

    fs.writeFileSync(
      path.join(EXPORT_DIR, 'README.md'),
      readme
    );

    console.log('üìã Created README with setup instructions');
    console.log('');

    // Show summary
    const stats = fs.statSync(exportFile);
    console.log('üìä EXPORT SUMMARY');
    console.log(`   üìÑ File size: ${(stats.size / 1024 / 1024).toFixed(2)} MB`);
    console.log(`   üìÅ Export directory: ${EXPORT_DIR}`);
    console.log(`   üïí Timestamp: ${new Date().toISOString()}`);

    console.log('');
    console.log('‚úÖ EXPORT COMPLETED SUCCESSFULLY!');
    console.log('');
    console.log('üìã NEXT STEPS FOR TARGET MACHINE:');
    console.log('   1. Copy the entire supabase-export/ directory to target machine');
    console.log('   2. Run: ./import-database.sh');
    console.log('   3. Verify data integrity');
    console.log('   4. Update environment variables');

  } catch (error) {
    console.error('‚ùå EXPORT FAILED:', error.message);
    process.exit(1);
  }
}

// Run the export
exportDatabase();

